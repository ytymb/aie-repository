{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68795c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id       f01       f02       f03        f04       f05       f06       f07  \\\n",
      "0   1 -0.149235 -2.826966 -0.522901  -4.198449  1.364943  0.815043 -1.195518   \n",
      "1   2 -1.966180 -4.877542  0.268367  -9.607791  0.097149  1.347185 -3.872575   \n",
      "2   3 -0.555964 -0.999920  0.209673 -14.119498 -1.808950 -0.006222 -4.651108   \n",
      "3   4 -2.049199 -5.600713 -1.664677  -6.263893 -5.224455  0.848351  1.407210   \n",
      "4   5 -0.220556  4.889479 -2.235840   6.450046  0.774389 -2.382625  2.584816   \n",
      "\n",
      "        f08       f09  ...       f29       f30       f31       f32       f33  \\\n",
      "0 -1.932232  2.396353  ... -0.159323  0.448015  0.572745  0.149916  0.878392   \n",
      "1 -0.395117  1.710068  ... -0.389212  1.383794  0.169876  0.043969 -0.963545   \n",
      "2  0.911944 -0.289037  ... -1.383970  3.044321 -0.182864  1.425649 -8.418598   \n",
      "3 -0.542080  0.119102  ... -2.713080  2.762637 -0.520796 -0.142455  1.668338   \n",
      "4  4.211856 -0.317889  ... -1.302872  2.478862  1.528610  1.098131  3.547087   \n",
      "\n",
      "        f34        f35    x_int_1    x_int_2  target  \n",
      "0 -0.679733   1.412751   0.421883   9.217167       1  \n",
      "1  1.006643  -2.488690   9.590124  24.772826       0  \n",
      "2 -4.629754  -0.439798   0.555919  41.800517       0  \n",
      "3  2.292810 -10.744916  11.476977  65.315860       0  \n",
      "4  2.517757  -9.364106  -1.078404  93.017870       0  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 39 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   id       18000 non-null  int64  \n",
      " 1   f01      18000 non-null  float64\n",
      " 2   f02      18000 non-null  float64\n",
      " 3   f03      18000 non-null  float64\n",
      " 4   f04      18000 non-null  float64\n",
      " 5   f05      18000 non-null  float64\n",
      " 6   f06      18000 non-null  float64\n",
      " 7   f07      18000 non-null  float64\n",
      " 8   f08      18000 non-null  float64\n",
      " 9   f09      18000 non-null  float64\n",
      " 10  f10      18000 non-null  float64\n",
      " 11  f11      18000 non-null  float64\n",
      " 12  f12      18000 non-null  float64\n",
      " 13  f13      18000 non-null  float64\n",
      " 14  f14      18000 non-null  float64\n",
      " 15  f15      18000 non-null  float64\n",
      " 16  f16      18000 non-null  float64\n",
      " 17  f17      18000 non-null  float64\n",
      " 18  f18      18000 non-null  float64\n",
      " 19  f19      18000 non-null  float64\n",
      " 20  f20      18000 non-null  float64\n",
      " 21  f21      18000 non-null  float64\n",
      " 22  f22      18000 non-null  float64\n",
      " 23  f23      18000 non-null  float64\n",
      " 24  f24      18000 non-null  float64\n",
      " 25  f25      18000 non-null  float64\n",
      " 26  f26      18000 non-null  float64\n",
      " 27  f27      18000 non-null  float64\n",
      " 28  f28      18000 non-null  float64\n",
      " 29  f29      18000 non-null  float64\n",
      " 30  f30      18000 non-null  float64\n",
      " 31  f31      18000 non-null  float64\n",
      " 32  f32      18000 non-null  float64\n",
      " 33  f33      18000 non-null  float64\n",
      " 34  f34      18000 non-null  float64\n",
      " 35  f35      18000 non-null  float64\n",
      " 36  x_int_1  18000 non-null  float64\n",
      " 37  x_int_2  18000 non-null  float64\n",
      " 38  target   18000 non-null  int64  \n",
      "dtypes: float64(37), int64(2)\n",
      "memory usage: 5.4 MB\n",
      "None\n",
      "                 id           f01           f02           f03           f04  \\\n",
      "count  18000.000000  18000.000000  18000.000000  18000.000000  18000.000000   \n",
      "mean    9000.500000     -0.418555      0.614251      0.004559      0.059000   \n",
      "std     5196.296758      2.178005      3.926778      1.000134      5.713672   \n",
      "min        1.000000    -10.014698    -15.510323     -4.031762    -23.663256   \n",
      "25%     4500.750000     -1.866134     -2.048192     -0.673127     -3.544964   \n",
      "50%     9000.500000     -0.465100      0.600291      0.003581      0.072826   \n",
      "75%    13500.250000      0.966393      3.229850      0.671390      3.689490   \n",
      "max    18000.000000      9.589975     15.417329      3.817025     26.815691   \n",
      "\n",
      "                f05           f06           f07           f08           f09  \\\n",
      "count  18000.000000  18000.000000  18000.000000  18000.000000  18000.000000   \n",
      "mean       0.405086      0.012123     -0.283473     -0.266880      0.255107   \n",
      "std        2.497581      0.987226      2.193891      2.081431      2.225776   \n",
      "min      -12.289308     -3.741536     -9.591425     -8.293319    -13.655742   \n",
      "25%       -1.153000     -0.653090     -1.743214     -1.688121     -1.177480   \n",
      "50%        0.485625      0.018765     -0.251263     -0.302463      0.350739   \n",
      "75%        2.075739      0.689304      1.195481      1.109589      1.764113   \n",
      "max       10.665184      3.528280      7.794627      8.892834      8.699629   \n",
      "\n",
      "       ...           f29           f30           f31           f32  \\\n",
      "count  ...  18000.000000  18000.000000  18000.000000  18000.000000   \n",
      "mean   ...     -0.139825      0.108568      0.007238      0.000904   \n",
      "std    ...      2.148834      2.234315      0.997861      1.002115   \n",
      "min    ...     -8.171469     -9.214171     -3.937091     -3.963063   \n",
      "25%    ...     -1.589638     -1.369266     -0.663023     -0.684164   \n",
      "50%    ...     -0.204785      0.158715      0.001912     -0.003157   \n",
      "75%    ...      1.254595      1.600671      0.677296      0.676558   \n",
      "max    ...      9.290667      8.794320      4.341030      3.781380   \n",
      "\n",
      "                f33           f34           f35       x_int_1       x_int_2  \\\n",
      "count  18000.000000  18000.000000  18000.000000  18000.000000  1.800000e+04   \n",
      "mean      -0.716862     -0.274520      0.344991      1.517339  2.576221e+01   \n",
      "std        3.913704      2.482890      4.927315     10.630850  5.423748e+01   \n",
      "min      -19.389908    -10.031559    -20.768452   -107.788145  1.895059e-07   \n",
      "25%       -3.286842     -1.897893     -2.752685     -2.018750  1.226029e+00   \n",
      "50%       -0.618472     -0.339901      0.573153      0.318011  6.581865e+00   \n",
      "75%        1.948803      1.314163      3.649794      4.212111  2.576847e+01   \n",
      "max       14.065595     10.639974     20.226291     94.891804  1.103449e+03   \n",
      "\n",
      "             target  \n",
      "count  18000.000000  \n",
      "mean       0.262611  \n",
      "std        0.440065  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n",
      "\n",
      "[8 rows x 39 columns]\n",
      "target\n",
      "0    0.737389\n",
      "1    0.262611\n",
      "Name: proportion, dtype: float64\n",
      "Пропуски:\n",
      " id         0\n",
      "f01        0\n",
      "f02        0\n",
      "f03        0\n",
      "f04        0\n",
      "f05        0\n",
      "f06        0\n",
      "f07        0\n",
      "f08        0\n",
      "f09        0\n",
      "f10        0\n",
      "f11        0\n",
      "f12        0\n",
      "f13        0\n",
      "f14        0\n",
      "f15        0\n",
      "f16        0\n",
      "f17        0\n",
      "f18        0\n",
      "f19        0\n",
      "f20        0\n",
      "f21        0\n",
      "f22        0\n",
      "f23        0\n",
      "f24        0\n",
      "f25        0\n",
      "f26        0\n",
      "f27        0\n",
      "f28        0\n",
      "f29        0\n",
      "f30        0\n",
      "f31        0\n",
      "f32        0\n",
      "f33        0\n",
      "f34        0\n",
      "f35        0\n",
      "x_int_1    0\n",
      "x_int_2    0\n",
      "target     0\n",
      "dtype: int64\n",
      "Типы столбцов:\n",
      " id           int64\n",
      "f01        float64\n",
      "f02        float64\n",
      "f03        float64\n",
      "f04        float64\n",
      "f05        float64\n",
      "f06        float64\n",
      "f07        float64\n",
      "f08        float64\n",
      "f09        float64\n",
      "f10        float64\n",
      "f11        float64\n",
      "f12        float64\n",
      "f13        float64\n",
      "f14        float64\n",
      "f15        float64\n",
      "f16        float64\n",
      "f17        float64\n",
      "f18        float64\n",
      "f19        float64\n",
      "f20        float64\n",
      "f21        float64\n",
      "f22        float64\n",
      "f23        float64\n",
      "f24        float64\n",
      "f25        float64\n",
      "f26        float64\n",
      "f27        float64\n",
      "f28        float64\n",
      "f29        float64\n",
      "f30        float64\n",
      "f31        float64\n",
      "f32        float64\n",
      "f33        float64\n",
      "f34        float64\n",
      "f35        float64\n",
      "x_int_1    float64\n",
      "x_int_2    float64\n",
      "target       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#импорт библиотек и первичный анализ датасета\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv('C:/Users/curse/Documents/aieprog/aie-repository/homeworks/HW06/S06-hw-dataset-02.csv')\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "target_col = 'target'\n",
    "print(df[target_col].value_counts(normalize=True))\n",
    "\n",
    "print(\"Пропуски:\\n\", df.isnull().sum())\n",
    "print(\"Типы столбцов:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ad2148",
   "metadata": {},
   "source": [
    "Провел первичный анализ датасета, пропусков нет, таргет 73.7% на 26.3%, то есть не совсем сбалансированный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c5c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В этом блоке определяем X и y\n",
    "X = df.drop(columns=['id', target_col])  # X - все столбцы кроме таргета и id \n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d791d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/Test-сплит и воспроизводимость\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db40c56",
   "metadata": {},
   "source": [
    "Мы фиксируем random_state (seed) чтобы при кажом запуске разбиение на test и train было одинаковым - это позволит нам сравнивать вывод честно и отлаживать код.\n",
    "Стратификация сохраняет пропорции классов в train и test - в нашем случае это особенно важно так как в таргете наблюдается дисбаланс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd6c5c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: DummyClassifier (most_frequent)\n",
      "accuracy = 0.6153\n",
      "f1       = 0.2660\n",
      "roc_auc  = 0.5027\n",
      "confusion_matrix:\n",
      "[[1964  691]\n",
      " [ 694  251]]\n",
      "\n",
      "Baseline: LogisticRegression\n",
      "accuracy = 0.8119\n",
      "f1       = 0.5607\n",
      "roc_auc  = 0.7977\n",
      "confusion_matrix:\n",
      "[[2491  164]\n",
      " [ 513  432]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def print_metrics(y_true, y_pred, y_proba=None, title=None): #функция для вывода метрик из примерного ноутбука\n",
    "    if title:\n",
    "        print(title)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"accuracy = {acc:.4f}\")\n",
    "    print(f\"f1       = {f1:.4f}\")\n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_proba)\n",
    "            print(f\"roc_auc  = {auc:.4f}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(\"confusion_matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# DummyClassifier\n",
    "dummy = DummyClassifier(strategy='stratified', random_state=42)\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "y_proba_dummy = dummy.predict_proba(X_test)[:, 1]\n",
    "print_metrics(y_test, y_pred_dummy, y_proba=y_proba_dummy, title=\"Baseline: DummyClassifier (most_frequent)\")\n",
    "\n",
    "# LogisticRegression через Pipeline\n",
    "lr_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "y_pred_lr = lr_pipe.predict(X_test)\n",
    "y_proba_lr = lr_pipe.predict_proba(X_test)[:, 1]\n",
    "print_metrics(y_test, y_pred_lr, y_proba=y_proba_lr, title=\"Baseline: LogisticRegression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7366693a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "accuracy = 0.8106\n",
      "f1       = 0.5727\n",
      "roc_auc  = 0.8089\n",
      "confusion_matrix:\n",
      "[[2461  194]\n",
      " [ 488  457]]\n",
      "\n",
      "RandomForestClassifier\n",
      "accuracy = 0.8858\n",
      "f1       = 0.7452\n",
      "roc_auc  = 0.9201\n",
      "confusion_matrix:\n",
      "[[2588   67]\n",
      " [ 344  601]]\n",
      "\n",
      "HistGradientBoostingClassifier\n",
      "accuracy = 0.8872\n",
      "f1       = 0.7578\n",
      "roc_auc  = 0.9141\n",
      "confusion_matrix:\n",
      "[[2559   96]\n",
      " [ 310  635]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Модели недели 6\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = 'f1'\n",
    "\n",
    "#DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt_params = {\n",
    "    'max_depth': [4, 6],          \n",
    "    'min_samples_leaf': [5]       \n",
    "}\n",
    "dt_cv = GridSearchCV(dt, dt_params, cv=3, scoring=scoring, n_jobs=-1)\n",
    "dt_cv.fit(X_train, y_train)\n",
    "print_metrics(y_test, dt_cv.predict(X_test), dt_cv.predict_proba(X_test)[:, 1], title=\"DecisionTreeClassifier\")\n",
    "\n",
    "#RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf_params = {\n",
    "    'max_depth': [6, None],      \n",
    "    'min_samples_leaf': [5]\n",
    "}\n",
    "rf_cv = GridSearchCV(rf, rf_params, cv=3, scoring=scoring, n_jobs=-1)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "print_metrics(y_test, rf_cv.predict(X_test), rf_cv.predict_proba(X_test)[:, 1], title=\"RandomForestClassifier\")\n",
    "\n",
    "#HistGradientBoostingClassifier\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "hgb_params = {\n",
    "    'max_depth': [4],            \n",
    "    'learning_rate': [0.1]        \n",
    "}\n",
    "hgb_cv = GridSearchCV(hgb, hgb_params, cv=3, scoring=scoring, n_jobs=-1)\n",
    "hgb_cv.fit(X_train, y_train)\n",
    "print_metrics(y_test, hgb_cv.predict(X_test), hgb_cv.predict_proba(X_test)[:, 1], title=\"HistGradientBoostingClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44586a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вторая функция для отображения метрик качества в формате json\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    else:\n",
    "        roc_auc = None\n",
    "    \n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": float(acc),\n",
    "        \"f1\": float(f1),\n",
    "        \"roc_auc\": float(roc_auc) if roc_auc is not None else None\n",
    "    }\n",
    "\n",
    "metrics_list = [\n",
    "    evaluate_model(dummy, X_test, y_test, \"DummyClassifier\"),\n",
    "    evaluate_model(lr_pipe, X_test, y_test, \"LogisticRegression\"),\n",
    "    evaluate_model(dt_cv, X_test, y_test, \"DecisionTreeClassifier\"),\n",
    "    evaluate_model(rf_cv, X_test, y_test, \"RandomForestClassifier\"),\n",
    "    evaluate_model(hgb_cv, X_test, y_test, \"HistGradientBoostingClassifier\")\n",
    "]\n",
    "metrics_dict = {m[\"model\"]: {k: v for k, v in m.items() if k != \"model\"} for m in metrics_list}\n",
    "\n",
    "with open('artifacts/metrics_test.json', 'w') as f: #Cохраняем общие метрики в отдельный файл\n",
    "    json.dump(metrics_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1701bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель по ROC-AUC: RandomForestClassifier (AUC = 0.9201)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Графики и диаграммы\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, precision_recall_curve, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"DummyClassifier\": dummy,\n",
    "    \"LogisticRegression\": lr_pipe,\n",
    "    \"DecisionTreeClassifier\": dt_cv,\n",
    "    \"RandomForestClassifier\": rf_cv,\n",
    "    \"HistGradientBoostingClassifier\": hgb_cv\n",
    "}\n",
    "\n",
    "best_model_name = None\n",
    "best_auc = -1\n",
    "best_model = None\n",
    "\n",
    "#Определяем лучшую модель по roc-auc\n",
    "for name, model in models.items():\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc_score = roc_auc_score(y_test, y_proba)\n",
    "    if auc_score > best_auc:\n",
    "        best_auc = auc_score\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "\n",
    "print(f\"Лучшая модель по ROC-AUC: {best_model_name} (AUC = {best_auc:.4f})\")\n",
    "\n",
    "#Рисуем графики\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#ROC-кривая\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {best_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC Curve — {best_model_name}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('artifacts/figures/roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "#Confusion Matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_best, cmap='Blues')\n",
    "plt.title(f'Confusion Matrix — {best_model_name}')\n",
    "plt.savefig('artifacts/figures/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "#Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba_best)\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall Curve — {best_model_name}')\n",
    "plt.grid(True)\n",
    "plt.savefig('artifacts/figures/pr_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99a478f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#используем test для оценки важности\n",
    "perm_imp = permutation_importance(\n",
    "    rf_cv,             #здесь использую сразу лучшую модель полученную в прошлом блоке\n",
    "    X_test, \n",
    "    y_test, \n",
    "    n_repeats=10,       \n",
    "    random_state=42, \n",
    "    scoring='f1'        \n",
    ")\n",
    "    \n",
    "indices = np.argsort(perm_imp.importances_mean)[::-1][:10]\n",
    "feature_names = X.columns[indices]\n",
    "importances = perm_imp.importances_mean[indices]\n",
    "std = perm_imp.importances_std[indices]\n",
    "\n",
    "#Визуализировал топ 10 признаков \n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(range(len(importances)), importances[::-1], xerr=std[::-1], color='skyblue')\n",
    "plt.yticks(range(len(importances)), [f for f in feature_names][::-1])\n",
    "plt.xlabel('Permutation Importance (Δ F1)')\n",
    "plt.title(f'Top-10 Important Features — {best_model_name}')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/permutation_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51cdef",
   "metadata": {},
   "source": [
    "Для лучшей модели (RandomForestClassifier) была рассчитана permutation importance на тестовой выборке. Наиболее значимыми оказался признак: `f_16`. Остальные признаки вносят существенно меньший вклад, а некоторые — практически не влияют на предсказание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ac7c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание недостающих артефактов\n",
    "\n",
    "models_for_search = {\n",
    "    \"DecisionTreeClassifier\": dt_cv,\n",
    "    \"RandomForestClassifier\": rf_cv,\n",
    "    \"HistGradientBoostingClassifier\": hgb_cv\n",
    "}\n",
    "\n",
    "search_summaries = {}\n",
    "for name, grid_search in models_for_search.items():\n",
    "    search_summaries[name] = {\n",
    "        \"best_params\": grid_search.best_params_,\n",
    "        \"cv_score\": float(grid_search.best_score_)\n",
    "    }\n",
    "with open('artifacts/search_summaries.json', 'w') as f:\n",
    "    json.dump(search_summaries, f, indent=4)\n",
    "\n",
    "joblib.dump(best_model, 'artifacts/best_model.joblib')\n",
    "\n",
    "best_model_meta = {\n",
    "    \"model_name\": best_model_name,\n",
    "    \"best_params\": models_for_search[best_model_name].best_params_,  # берём из GridSearchCV\n",
    "    \"cv_score\": float(models_for_search[best_model_name].best_score_),\n",
    "    \"test_metrics\": metrics_dict[best_model_name]\n",
    "}\n",
    "\n",
    "with open('artifacts/best_model_meta.json', 'w') as f:\n",
    "    json.dump(best_model_meta, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
