# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (18000, 39)
- Целевая переменная: `target` (бинарная классификация: 0 / 1)
- Признаки:
  - Числовые: `f01`–`f35`, `x_int_1`, `x_int_2` — все типа `float64`
  - Категориальные/подобные: отсутствуют
  - Столбец `id` — не используется как признак (идентификатор)

## 2. Protocol

- Разбиение: train/test в соотношении 0.8 / 0.2, с фиксированным `random_state=42` и стратификацией по `y`.
- Подбор: CV на train с использованием `GridSearchCV`, 3 фолда (`cv=3`), метрика `f1` (так как задача бинарная).
- - Метрики: accuracy, F1, ROC-AUC.
  - Accuracy — общая точность, но может быть обманчива при дисбалансе.
  - F1 — гармоническое среднее precision и recall — важна для бинарной классификации.
  - ROC-AUC — показывает способность модели отделять классы, устойчив к дисбалансу.

## 3. Models

Сравнивались следующие модели:

- DummyClassifier (baseline, `strategy='stratified'`) — предсказывает случайно с сохранением долей классов.
- LogisticRegression (baseline) — через Pipeline с StandardScaler.
- DecisionTreeClassifier - подбирался `max_depth` и `min_samples_leaf`.
- RandomForestClassifier - подбирался `max_depth`, `min_samples_leaf`, `n_estimators=50`.
- Один boosting (HistGradientBoosting) — подбирался `max_depth`, `learning_rate`.

Гиперпараметры:
- Все модели оптимизировались через `GridSearchCV` с `scoring='f1'` на train.
- Для деревьев и лесов контролировалась сложность (глубина, минимальное число объектов в листе).
- Использовалось `n_jobs=-1` для ускорения.

## 4. Results

Финальные метрики на тестовой выборке:

| Модель                      | Accuracy | F1-score | ROC-AUC |
|----------------------------|:--------:|:--------:|:-------:|
| DummyClassifier            |   0.62    |   0.27    |  0.50    |
| LogisticRegression         |   0.81    |   0.56    |  0.80    |
| DecisionTreeClassifier     |   0.81    |   0.57    |  0.81    |
| RandomForestClassifier     |   0.886   |   0.745   |  0.920   |
| HistGradientBoosting       |   0.887   |   0.758   |  0.914   |

- Победитель по ROC-AUC **RandomForestClassifier** (ROC-AUC = 0.920).
- Все метрики здесь округлены, более подробные значения вы можете посмотреть в файле **HW06/artifacts/metrics_test.json**

## 5. Analysis

- При изменении `random_state` (например, на 0, 41, 43) результаты моделей меняются незначительно — разница в ROC-AUC не превышает ±0.01, что говорит о стабильности протокола.


- Ошибки: 
- Confusion matrix для `RandomForestClassifier`:
[[2588   67]
 [ 344  601]]
- Модель очень хорошо распознаёт класс 0 (TN = 2588, FP = 67) — ложных срабатываний мало.
- Класс 1 распознаётся хуже: 344 случая были пропущены (FN), что составляет ~36% от всех положительных примеров. В целом это подтверждает **Bootstrap-интуицию** модели.
- Это указывает на несбалансированную чувствительность модели: она "осторожнее" относится к предсказанию класса 1.


- Permutation importance (top-10 признаков):
1. `f_16` — 0.18
2. `f_19` — 0.05
3. `f_01` — 0.05
4. `f_23` — 0.04
5. `f_12` — 0.039
6. `f_02` — 0.035
7. `f_13` — 0.027
8. `f_34` — 0.026
9. `f_04` — 0.025
10. `f_30` — 0.024


## 6. Conclusion

1. **Деревья и ансамбли работают лучше простых моделей** — RandomForest показал лучшие результаты, что согласуется с теорией: ансамбли устойчивы к переобучению и хорошо работают с нелинейными зависимостями.
2. **Честный ML-протокол важен** — использование `random_state`, `stratify`, `cv=3`, одинаковых метрик и тестовой выборки только один раз позволяет объективно сравнивать модели.
3. **Baseline’ы — обязательны** — Dummy и LogisticRegression показали, что даже простая модель может дать хороший результат, а более сложные алгоритмы должны его превосходить.

